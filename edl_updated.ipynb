{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anandt555/BigData-Practice/blob/main/edl_updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evidential deep learning**"
      ],
      "metadata": {
        "id": "Jo6JG99C04TE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evidential deep learning With MNIST**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rQDGUnodJ9xI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "# Download MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=1000, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "# LeNet model with Dirichlet distribution for Evidential Deep Learning\n",
        "class LeNetDirichlet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNetDirichlet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, kernel_size=5, stride=1, padding=0)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5, stride=1, padding=0)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(torch.relu(self.conv1(x)))\n",
        "        x = self.pool2(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        alpha = torch.abs(x) + 1  # Use absolute values for simplicity, adjust as needed\n",
        "\n",
        "        u = 10 / torch.sum(alpha, dim=1, keepdim=True)\n",
        "\n",
        "        prob = alpha / torch.sum(alpha, 1, keepdim=True)\n",
        "\n",
        "        return prob, u, alpha\n",
        "\n",
        "# Train LeNet model with Dirichlet distribution for Evidential Deep Learning\n",
        "lenet_dirichlet = LeNetDirichlet()\n",
        "criterion_dirichlet = nn.CrossEntropyLoss()\n",
        "optimizer_dirichlet = optim.Adam(lenet_dirichlet.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    lenet_dirichlet.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer_dirichlet.zero_grad()\n",
        "        outputs, _, _ = lenet_dirichlet(inputs)\n",
        "        loss = criterion_dirichlet(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_dirichlet.step()\n",
        "\n",
        "    lenet_dirichlet.eval()\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in train_loader:\n",
        "            outputs, _, _ = lenet_dirichlet(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs, _, _ = lenet_dirichlet(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "    print('epoch %d - training accuracy: %2.4f \\t testing accuracy: %2.4f' %\n",
        "          (epoch+1, correct_train / total_train, correct_test / total_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2KIrXlcCqzW",
        "outputId": "85e331f7-6034-44a0-b600-4e7a9159a785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 145697183.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 24853445.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 112291016.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 10264293.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 - training accuracy: 0.7368 \t testing accuracy: 0.7424\n",
            "epoch 2 - training accuracy: 0.9094 \t testing accuracy: 0.9168\n",
            "epoch 3 - training accuracy: 0.9518 \t testing accuracy: 0.9555\n",
            "epoch 4 - training accuracy: 0.9606 \t testing accuracy: 0.9627\n",
            "epoch 5 - training accuracy: 0.9655 \t testing accuracy: 0.9673\n",
            "epoch 6 - training accuracy: 0.9694 \t testing accuracy: 0.9710\n",
            "epoch 7 - training accuracy: 0.9725 \t testing accuracy: 0.9744\n",
            "epoch 8 - training accuracy: 0.9746 \t testing accuracy: 0.9762\n",
            "epoch 9 - training accuracy: 0.9767 \t testing accuracy: 0.9784\n",
            "epoch 10 - training accuracy: 0.9789 \t testing accuracy: 0.9790\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Assuming you have the original MNIST dataset loaded\n",
        "transform_display = transforms.Compose([transforms.ToPILImage(), transforms.Resize((28, 28))])\n",
        "\n",
        "# Display the original image\n",
        "test_image, test_label = test_dataset[5]  # Access the 5th test image\n",
        "plt.imshow(transform_display(test_image), cmap='gray')\n",
        "plt.title(f'True Label: {test_label}')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "lenet_dirichlet.eval()\n",
        "\n",
        "input_image = test_image.unsqueeze(0)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs, uncertainty, alpha = lenet_dirichlet(input_image)\n",
        "\n",
        "probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "print(\"Predicted Probabilities:\", probabilities)\n",
        "print(\"Uncertainty:\", uncertainty)\n",
        "print(\"Alpha Parameters:\", alpha)\n",
        "#print(\"True Label:\", test_label.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "vqv0s6bVMWBR",
        "outputId": "5bc85390-78d3-41e3-fbd0-40187761d2b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Probabilities: tensor([[0.0856, 0.2289, 0.0857, 0.0857, 0.0857, 0.0857, 0.0857, 0.0856, 0.0857,\n",
            "         0.0857]])\n",
            "Uncertainty: tensor([[0.0122]])\n",
            "Alpha Parameters: tensor([[  1.0882, 805.4111,   1.2244,   1.4984,   1.7173,   1.2568,   1.7364,\n",
            "           1.1229,   1.5463,   1.4140]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evidential deep learning with CIFAR10**"
      ],
      "metadata": {
        "id": "QJCOzpStKMZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "# Download CIFAR-10 dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data1', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data1', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# LeNet model with Dirichlet distribution for Evidential Deep Learning\n",
        "class LeNetDirichletCIFAR(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNetDirichletCIFAR, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2)  # Adjust input channels\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(8*8*64, 512)  # Adjust the input size for fully connected layer\n",
        "        self.fc2 = nn.Linear(512, 10)  # Adjust output classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(torch.relu(self.conv1(x)))\n",
        "        x = self.pool2(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 8*8*64)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        alpha = torch.abs(x) + 1  # Use absolute values for simplicity, adjust as needed\n",
        "\n",
        "        u = 10 / torch.sum(alpha, dim=1, keepdim=True)\n",
        "\n",
        "        prob = alpha / torch.sum(alpha, 1, keepdim=True)\n",
        "\n",
        "        return prob, u, alpha\n",
        "\n",
        "# Train LeNet model with Dirichlet distribution for Evidential Deep Learning\n",
        "lenet_dirichlet_CIFAR = LeNetDirichletCIFAR()\n",
        "criterion_dirichlet = nn.CrossEntropyLoss()\n",
        "optimizer_dirichlet = optim.Adam(lenet_dirichlet_CIFAR.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(20):\n",
        "    lenet_dirichlet_CIFAR.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer_dirichlet.zero_grad()\n",
        "        outputs, _, _ = lenet_dirichlet_CIFAR(inputs)\n",
        "        loss = criterion_dirichlet(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_dirichlet.step()\n",
        "\n",
        "    lenet_dirichlet_CIFAR.eval()\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in train_loader:\n",
        "            outputs, _, _ = lenet_dirichlet_CIFAR(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs, _, _ = lenet_dirichlet_CIFAR(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "    print('epoch %d - training accuracy: %2.4f \\t testing accuracy: %2.4f' %\n",
        "          (epoch+1, correct_train / total_train, correct_test / total_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNPCYSE53HzY",
        "outputId": "9d14d571-254c-44f7-a6a4-a4d9ff0932f6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data1/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 68956165.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data1/cifar-10-python.tar.gz to ./data1\n",
            "Files already downloaded and verified\n",
            "epoch 1 - training accuracy: 0.5139 \t testing accuracy: 0.5109\n",
            "epoch 2 - training accuracy: 0.5936 \t testing accuracy: 0.5756\n",
            "epoch 3 - training accuracy: 0.6489 \t testing accuracy: 0.6136\n",
            "epoch 4 - training accuracy: 0.6811 \t testing accuracy: 0.6280\n",
            "epoch 5 - training accuracy: 0.7188 \t testing accuracy: 0.6522\n",
            "epoch 6 - training accuracy: 0.7481 \t testing accuracy: 0.6740\n",
            "epoch 7 - training accuracy: 0.7573 \t testing accuracy: 0.6670\n",
            "epoch 8 - training accuracy: 0.7832 \t testing accuracy: 0.6803\n",
            "epoch 9 - training accuracy: 0.7994 \t testing accuracy: 0.6790\n",
            "epoch 10 - training accuracy: 0.8128 \t testing accuracy: 0.6822\n",
            "epoch 11 - training accuracy: 0.8190 \t testing accuracy: 0.6809\n",
            "epoch 12 - training accuracy: 0.8300 \t testing accuracy: 0.6826\n",
            "epoch 13 - training accuracy: 0.8359 \t testing accuracy: 0.6754\n",
            "epoch 14 - training accuracy: 0.8394 \t testing accuracy: 0.6812\n",
            "epoch 15 - training accuracy: 0.8513 \t testing accuracy: 0.6797\n",
            "epoch 16 - training accuracy: 0.8552 \t testing accuracy: 0.6814\n",
            "epoch 17 - training accuracy: 0.8484 \t testing accuracy: 0.6749\n",
            "epoch 18 - training accuracy: 0.8648 \t testing accuracy: 0.6680\n",
            "epoch 19 - training accuracy: 0.8657 \t testing accuracy: 0.6752\n",
            "epoch 20 - training accuracy: 0.8678 \t testing accuracy: 0.6816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Assuming you have the original CIFAR-10 dataset loaded\n",
        "transform_display = transforms.Compose([transforms.ToPILImage(), transforms.Resize((32, 32))])\n",
        "\n",
        "# Display the original image\n",
        "test_image, true_label = test_dataset[5]  # Access the 5th test image\n",
        "plt.imshow(transform_display(test_image), cmap='gray')\n",
        "plt.title(f'True Label: {true_label}')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Continue with the rest of the code for inference\n",
        "lenet_dirichlet_CIFAR.eval()\n",
        "class_labels = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
        "\n",
        "\n",
        "# Reshape the input image to match the model's input size\n",
        "input_image = test_image.unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs, uncertainty, alpha = lenet_dirichlet_CIFAR(input_image)\n",
        "\n",
        "predicted_probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "predicted_class = torch.argmax(predicted_probabilities, dim=1).item()\n",
        "\n",
        "print(\"Predicted Probabilities:\", predicted_probabilities)\n",
        "print(\"Predicted Class:\", class_labels[predicted_class])\n",
        "print(\"Uncertainty:\", uncertainty.item())\n",
        "print(\"Alpha Parameters:\", alpha.squeeze().tolist())  # Convert alpha tensor to list for easier printing\n",
        "print(\"True Label:\", class_labels[true_label])  # Convert true label tensor to Python scalar for display"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "Ppu_ayQhTx7-",
        "outputId": "2493250f-661f-44ff-c300-7d1f2800ea33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Probabilities: tensor([[0.0863, 0.0863, 0.0864, 0.0863, 0.0865, 0.0863, 0.2229, 0.0863, 0.0863,\n",
            "         0.0863]])\n",
            "Predicted Class: Frog\n",
            "Uncertainty: 0.04694695770740509\n",
            "Alpha Parameters: [1.0372369289398193, 1.036574363708496, 1.1590166091918945, 1.082773208618164, 1.4299254417419434, 1.030117154121399, 203.13356018066406, 1.0300381183624268, 1.0586154460906982, 1.0084997415542603]\n",
            "True Label: Frog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Evidential deep learning And Mixup***"
      ],
      "metadata": {
        "id": "39CmP9BL0js7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Evidential deep learning And Mixup MNIST**"
      ],
      "metadata": {
        "id": "Mj7_9qsdKVEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "# Download MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# LeNet model with Dirichlet distribution for Evidential Deep Learning and mixup\n",
        "class LeNetDirichletMixup(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNetDirichletMixup, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, kernel_size=5, stride=1, padding=0)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5, stride=1, padding=0)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(torch.relu(self.conv1(x)))\n",
        "        x = self.pool2(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        alpha = torch.abs(x) + 1  # Use absolute values for simplicity, adjust as needed\n",
        "\n",
        "        u = 10 / torch.sum(alpha, dim=1, keepdim=True)\n",
        "\n",
        "        prob = alpha / torch.sum(alpha, 1, keepdim=True)\n",
        "\n",
        "        return prob, u, alpha\n",
        "\n",
        "# # Mixup function for Evidential Deep Learning\n",
        "# def mixup_data(x, y, alpha=0.1):\n",
        "#     lam = np.random.beta(alpha, alpha)\n",
        "#     batch_size = x.size()[0]\n",
        "#     index = torch.randperm(batch_size).to(x.device)\n",
        "#     mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "#     mixed_y = lam * y + (1 - lam) * y[index, :]\n",
        "#     return mixed_x, mixed_y\n",
        "# epoch 1 - training accuracy: 0.6890 \t testing accuracy: 0.6892\n",
        "# epoch 2 - training accuracy: 0.6864 \t testing accuracy: 0.6874\n",
        "\n",
        "def mixup_data(x, y, alpha=0.1):\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size)\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    # Convert labels to one-hot encoding\n",
        "    y_onehot = torch.zeros(y.size(0), 10).to(x.device)\n",
        "    y_onehot.scatter_(1, y.view(-1, 1).long(), 1)\n",
        "    mixed_y = lam * y_onehot + (1 - lam) * y_onehot[index, :]\n",
        "    mixed_y = mixed_y.argmax(dim=1)\n",
        "    return mixed_x, mixed_y\n",
        "\n",
        "# Train LeNet model with Dirichlet distribution and mixup for Evidential Deep Learning\n",
        "lenet_dirichlet_mixup = LeNetDirichletMixup()\n",
        "criterion_dirichlet = nn.CrossEntropyLoss()\n",
        "optimizer_dirichlet_mixup = optim.Adam(lenet_dirichlet_mixup.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    lenet_dirichlet_mixup.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = mixup_data(inputs, labels.unsqueeze(1))  # Assuming labels are one-dimensional\n",
        "\n",
        "        optimizer_dirichlet_mixup.zero_grad()\n",
        "        outputs, _, _ = lenet_dirichlet_mixup(inputs)\n",
        "        labels = labels.squeeze().long()\n",
        "\n",
        "        loss = criterion_dirichlet(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_dirichlet_mixup.step()\n",
        "\n",
        "    lenet_dirichlet_mixup.eval()\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in train_loader:\n",
        "            outputs, _, _ = lenet_dirichlet_mixup(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs, _, _ = lenet_dirichlet_mixup(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "    print('epoch %d - training accuracy: %2.4f \\t testing accuracy: %2.4f' %\n",
        "          (epoch+1, correct_train / total_train, correct_test / total_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPKXdGzkbiiY",
        "outputId": "9eb10cd7-f609-459d-80f0-71faa83384a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 - training accuracy: 0.9700 \t testing accuracy: 0.9743\n",
            "epoch 2 - training accuracy: 0.9810 \t testing accuracy: 0.9811\n",
            "epoch 3 - training accuracy: 0.9849 \t testing accuracy: 0.9842\n",
            "epoch 4 - training accuracy: 0.9886 \t testing accuracy: 0.9863\n",
            "epoch 5 - training accuracy: 0.9895 \t testing accuracy: 0.9871\n",
            "epoch 6 - training accuracy: 0.9905 \t testing accuracy: 0.9888\n",
            "epoch 7 - training accuracy: 0.9928 \t testing accuracy: 0.9898\n",
            "epoch 8 - training accuracy: 0.9933 \t testing accuracy: 0.9896\n",
            "epoch 9 - training accuracy: 0.9933 \t testing accuracy: 0.9892\n",
            "epoch 10 - training accuracy: 0.9940 \t testing accuracy: 0.9914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Assuming you have the original MNIST dataset loaded\n",
        "transform_display = transforms.Compose([transforms.ToPILImage(), transforms.Resize((28, 28))])\n",
        "\n",
        "# Display the original image\n",
        "test_image, test_label = test_dataset[5]\n",
        "plt.imshow(transform_display(test_image), cmap='gray')\n",
        "plt.title(f'True Label: {test_label}')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "input_image = test_image.unsqueeze(0)\n",
        "# Continue with the rest of the code for inference\n",
        "lenet_dirichlet_mixup.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs, uncertainty, alpha = lenet_dirichlet_mixup(input_image)\n",
        "\n",
        "probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "print(\"Predicted Probabilities:\", probabilities)\n",
        "print(\"Uncertainty:\", uncertainty)\n",
        "print(\"Alpha Parameters:\", alpha)\n",
        "print(\"True Label:\", test_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "id": "OJASLwk5dArJ",
        "outputId": "2482c31b-f4b7-4bc4-9d90-e48d118b748d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Probabilities: tensor([[0.0854, 0.2315, 0.0854, 0.0854, 0.0854, 0.0854, 0.0854, 0.0854, 0.0854,\n",
            "         0.0854]])\n",
            "Uncertainty: tensor([[0.0019]])\n",
            "Alpha Parameters: tensor([[1.1658e+00, 5.2202e+03, 1.5734e+00, 1.1877e+00, 1.2903e+00, 1.1423e+00,\n",
            "         1.1165e+00, 1.1213e+00, 1.7402e+00, 1.0298e+00]])\n",
            "True Label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Evidential deep learning And Mixup CIFAR10**"
      ],
      "metadata": {
        "id": "qhpQUdbmKio7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "# Download CIFAR-10 dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data1', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data1', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# LeNet model with Dirichlet distribution for Evidential Deep Learning and mixup\n",
        "class LeNetDirichletCIFARMixup(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNetDirichletCIFARMixup, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(8*8*64, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(torch.relu(self.conv1(x)))\n",
        "        x = self.pool2(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 8*8*64)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        alpha = torch.abs(x) + 1\n",
        "\n",
        "        u = 10 / torch.sum(alpha, dim=1, keepdim=True)\n",
        "\n",
        "        prob = alpha / torch.sum(alpha, 1, keepdim=True)\n",
        "\n",
        "        return prob, u, alpha\n",
        "\n",
        "# Updated mixup function for Evidential Deep Learning\n",
        "def mixup_data(x, y, alpha=0.1):\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size)\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "\n",
        "    # Convert labels to one-hot encoding\n",
        "    y_onehot = torch.zeros(y.size(0), 10).to(x.device)\n",
        "    y_onehot.scatter_(1, y.view(-1, 1).long(), 1)\n",
        "    mixed_y = lam * y_onehot + (1 - lam) * y_onehot[index, :]\n",
        "    mixed_y = mixed_y.argmax(dim=1)\n",
        "    return mixed_x, mixed_y\n",
        "\n",
        "\n",
        "# Train LeNet model with Dirichlet distribution and mixup for Evidential Deep Learning\n",
        "lenet_dirichlet_CIFAR_mixup = LeNetDirichletCIFARMixup()\n",
        "criterion_dirichlet = nn.CrossEntropyLoss()\n",
        "optimizer_dirichlet = optim.Adam(lenet_dirichlet_CIFAR_mixup.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(20):\n",
        "    lenet_dirichlet_CIFAR_mixup.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = mixup_data(inputs, labels.unsqueeze(1))  # Assuming labels are one-dimensional\n",
        "\n",
        "        optimizer_dirichlet.zero_grad()\n",
        "        outputs, _, _ = lenet_dirichlet_CIFAR_mixup(inputs)\n",
        "\n",
        "        # Cast labels back to Long data type\n",
        "        labels = labels.squeeze().long()\n",
        "\n",
        "        loss = criterion_dirichlet(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_dirichlet.step()\n",
        "\n",
        "    lenet_dirichlet_CIFAR_mixup.eval()\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in train_loader:\n",
        "            outputs, _, _ = lenet_dirichlet_CIFAR_mixup(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs, _, _ = lenet_dirichlet_CIFAR_mixup(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "    print('epoch %d - training accuracy: %2.4f \\t testing accuracy: %2.4f' %\n",
        "          (epoch+1, correct_train / total_train, correct_test / total_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKoScADoLbMY",
        "outputId": "37cb1974-9193-490d-a29d-071731e3e9e3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "epoch 1 - training accuracy: 0.5069 \t testing accuracy: 0.5043\n",
            "epoch 2 - training accuracy: 0.5897 \t testing accuracy: 0.5683\n",
            "epoch 3 - training accuracy: 0.6323 \t testing accuracy: 0.6005\n",
            "epoch 4 - training accuracy: 0.6780 \t testing accuracy: 0.6246\n",
            "epoch 5 - training accuracy: 0.7125 \t testing accuracy: 0.6485\n",
            "epoch 6 - training accuracy: 0.7306 \t testing accuracy: 0.6515\n",
            "epoch 7 - training accuracy: 0.7452 \t testing accuracy: 0.6604\n",
            "epoch 8 - training accuracy: 0.7671 \t testing accuracy: 0.6730\n",
            "epoch 9 - training accuracy: 0.7869 \t testing accuracy: 0.6823\n",
            "epoch 10 - training accuracy: 0.7992 \t testing accuracy: 0.6848\n",
            "epoch 11 - training accuracy: 0.7975 \t testing accuracy: 0.6717\n",
            "epoch 12 - training accuracy: 0.8220 \t testing accuracy: 0.6890\n",
            "epoch 13 - training accuracy: 0.8237 \t testing accuracy: 0.6861\n",
            "epoch 14 - training accuracy: 0.8350 \t testing accuracy: 0.6922\n",
            "epoch 15 - training accuracy: 0.8439 \t testing accuracy: 0.6922\n",
            "epoch 16 - training accuracy: 0.8381 \t testing accuracy: 0.6833\n",
            "epoch 17 - training accuracy: 0.8501 \t testing accuracy: 0.6852\n",
            "epoch 18 - training accuracy: 0.8546 \t testing accuracy: 0.6918\n",
            "epoch 19 - training accuracy: 0.8611 \t testing accuracy: 0.6899\n",
            "epoch 20 - training accuracy: 0.8577 \t testing accuracy: 0.6826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Assuming you have the original CIFAR-10 dataset loaded\n",
        "transform_display = transforms.Compose([transforms.ToPILImage(), transforms.Resize((32, 32))])\n",
        "\n",
        "# Display the original image\n",
        "test_image, true_label = test_dataset[5]  # Access the 5th test image\n",
        "plt.imshow(transform_display(test_image), cmap='gray')\n",
        "plt.title(f'True Label: {true_label}')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Continue with the rest of the code for inference\n",
        "lenet_dirichlet_CIFAR_mixup.eval()\n",
        "class_labels = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
        "\n",
        "input_image = test_image.unsqueeze(0)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs, uncertainty, alpha = lenet_dirichlet_CIFAR_mixup(input_image)\n",
        "\n",
        "predicted_probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "predicted_class = torch.argmax(predicted_probabilities, dim=1).item()\n",
        "\n",
        "print(\"Predicted Probabilities:\", predicted_probabilities)\n",
        "print(\"Predicted Class:\", class_labels[predicted_class])\n",
        "print(\"Uncertainty:\", uncertainty.item())\n",
        "print(\"Alpha Parameters:\", alpha.squeeze().tolist())\n",
        "print(\"True Label:\", class_labels[true_label])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "FeCiZZdgNdeT",
        "outputId": "fd022825-c951-4775-d1f2-33e07ded9fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Probabilities: tensor([[0.0855, 0.0855, 0.0855, 0.0855, 0.0855, 0.0855, 0.2303, 0.0855, 0.0855,\n",
            "         0.0855]])\n",
            "Predicted Class: Frog\n",
            "Uncertainty: 0.007052295375615358\n",
            "Alpha Parameters: [1.1298736333847046, 1.167922019958496, 1.150836706161499, 1.6215661764144897, 1.2880825996398926, 1.050527572631836, 1406.2833251953125, 1.4581726789474487, 1.2837660312652588, 1.5439786911010742]\n",
            "True Label: Frog\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrQp33IEd6XCFmYVZ1/5q8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}